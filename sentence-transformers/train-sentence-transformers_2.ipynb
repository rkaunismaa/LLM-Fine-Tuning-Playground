{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saturday, June 8, 2024\n",
    "\n",
    "[Training and Finetuning Embedding Models with Sentence Transformers v3](https://huggingface.co/blog/train-sentence-transformers)\n",
    "\n",
    "This notebook was manually created from the above document. \n",
    "\n",
    "*** mamba activate ftllm ***\n",
    "\n",
    "This notebook was copied from 'sentence-transformers/train-sentence-transformers.ipynb' to retain the original output, then use this to experiment with some of the settings, and then compare the results with this first notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only target the 4090 ...\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells were generated by Chat Gpt 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA GeForce RTX 4090\n",
      "Compute Capability: (8, 9)\n",
      "Your GPU supports FP16 (half-precision).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "fp16 = False\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    compute_capability = torch.cuda.get_device_capability(0)\n",
    "    print(f\"GPU Name: {gpu_name}\")\n",
    "    print(f\"Compute Capability: {compute_capability}\")\n",
    "    if compute_capability[0] >= 5:\n",
    "        print(\"Your GPU supports FP16 (half-precision).\")\n",
    "        fp16 = True\n",
    "    else:\n",
    "        print(\"Your GPU does not support FP16 (half-precision).\")\n",
    "else:\n",
    "    print(\"No CUDA-compatible GPU found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA GeForce RTX 4090\n",
      "Compute Capability: (8, 9)\n",
      "Your GPU supports BF16 (bfloat16).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "bf16 = False\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    compute_capability = torch.cuda.get_device_capability(0)\n",
    "    print(f\"GPU Name: {gpu_name}\")\n",
    "    print(f\"Compute Capability: {compute_capability}\")\n",
    "    if compute_capability >= (8, 0):  # Ampere architecture and above\n",
    "        print(\"Your GPU supports BF16 (bfloat16).\")\n",
    "        bf16 = True\n",
    "    else:\n",
    "        print(\"Your GPU does not support BF16 (bfloat16).\")\n",
    "else:\n",
    "    print(\"No CUDA-compatible GPU found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need these next two statements, otherwise we get ...\n",
    "# NotImplementedError: Using RTX 4000 series doesn't support faster communication broadband via P2P or IB. Please set `NCCL_P2P_DISABLE=\\\"1\\\"` and `NCCL_IB_DISABLE=\\\"1\\\" or use `accelerate launch` which will do this automatically.\"\n",
    "# ... when we try to initialize SentenceTransformerTrainingArguments further on down ... \n",
    "os.environ[\"NCCL_P2P_DISABLE\"]=\"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name microsoft/mpnet-base. Creating a new one with mean pooling.\n",
      "/home/rob/miniforge3/envs/ftllm/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a model to finetune with 2. (Optional) model card data\n",
    "model = SentenceTransformer(\n",
    "    \"microsoft/mpnet-base\",\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"MPNet base trained on AllNLI triplets\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# 7m 31.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load a dataset to finetune on\n",
    "dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\")\n",
    "train_dataset = dataset[\"train\"].select(range(100_000))\n",
    "eval_dataset = dataset[\"dev\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "# 37.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define a loss function\n",
    "loss = MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweak some of the below defaults ... default for both was 16\n",
    "# 1024 was too big!\n",
    "# 512  was too big!\n",
    "# 256  was too big!\n",
    "train_batch_size = 128\n",
    "eval_batch_size = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override a few of the below defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (Optional) Specify training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/mpnet-base-all-nli-triplet\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=1,\n",
    "    # per_device_train_batch_size=16,\n",
    "    # per_device_eval_batch_size=16,\n",
    "    # Override!\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    warmup_ratio=0.1,\n",
    "    # fp16=True,  # Set to False if GPU can't handle FP16\n",
    "    # bf16=False,  # Set to True if GPU supports BF16\n",
    "    # Override!\n",
    "    # If we try to set both of the below values to True, we get the following error ...\n",
    "    # ValueError: At most one of fp16 and bf16 can be True, but not both,\n",
    "    # so set the correct values for the 4090 ...\n",
    "    # fp16 = fp16,\n",
    "    # bf16 = bf16, \n",
    "    fp16 = False, \n",
    "    bf16 = True, \n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    # eval_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"mpnet-base-all-nli-triplet\",  # Used in W&B if `wandb` is installed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all-nli-dev_cosine_accuracy': 0.6210510328068044,\n",
       " 'all-nli-dev_dot_accuracy': 0.45337181044957475,\n",
       " 'all-nli-dev_manhattan_accuracy': 0.6831713244228432,\n",
       " 'all-nli-dev_euclidean_accuracy': 0.62226609963548,\n",
       " 'all-nli-dev_max_accuracy': 0.6831713244228432}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. (Optional) Create an evaluator & evaluate the base model\n",
    "dev_evaluator = TripletEvaluator(\n",
    "    anchors=eval_dataset[\"anchor\"],\n",
    "    positives=eval_dataset[\"positive\"],\n",
    "    negatives=eval_dataset[\"negative\"],\n",
    "    name=\"all-nli-dev\",\n",
    ")\n",
    "dev_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create a trainer & train\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrobkayinto\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rob/Data/Documents/Github/rkaunismaa/LLM-Fine-Tuning-Playground/sentence-transformers/wandb/run-20240608_112540-swzagsbh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/robkayinto/sentence-transformers/runs/swzagsbh/workspace' target=\"_blank\">mpnet-base-all-nli-triplet</a></strong> to <a href='https://wandb.ai/robkayinto/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/robkayinto/sentence-transformers' target=\"_blank\">https://wandb.ai/robkayinto/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/robkayinto/sentence-transformers/runs/swzagsbh/workspace' target=\"_blank\">https://wandb.ai/robkayinto/sentence-transformers/runs/swzagsbh/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 12:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>All-nli-dev Cosine Accuracy</th>\n",
       "      <th>All-nli-dev Dot Accuracy</th>\n",
       "      <th>All-nli-dev Manhattan Accuracy</th>\n",
       "      <th>All-nli-dev Euclidean Accuracy</th>\n",
       "      <th>All-nli-dev Max Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.750700</td>\n",
       "      <td>1.232818</td>\n",
       "      <td>0.827461</td>\n",
       "      <td>0.174362</td>\n",
       "      <td>0.826245</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>0.827461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.693100</td>\n",
       "      <td>1.155465</td>\n",
       "      <td>0.845535</td>\n",
       "      <td>0.154162</td>\n",
       "      <td>0.843560</td>\n",
       "      <td>0.843104</td>\n",
       "      <td>0.845535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.695000</td>\n",
       "      <td>1.144550</td>\n",
       "      <td>0.859204</td>\n",
       "      <td>0.136847</td>\n",
       "      <td>0.853129</td>\n",
       "      <td>0.854648</td>\n",
       "      <td>0.859204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.598600</td>\n",
       "      <td>1.003252</td>\n",
       "      <td>0.875759</td>\n",
       "      <td>0.116039</td>\n",
       "      <td>0.872418</td>\n",
       "      <td>0.871962</td>\n",
       "      <td>0.875759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.541500</td>\n",
       "      <td>0.945530</td>\n",
       "      <td>0.883354</td>\n",
       "      <td>0.109812</td>\n",
       "      <td>0.878038</td>\n",
       "      <td>0.878797</td>\n",
       "      <td>0.883354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.502100</td>\n",
       "      <td>0.860337</td>\n",
       "      <td>0.900516</td>\n",
       "      <td>0.094623</td>\n",
       "      <td>0.893682</td>\n",
       "      <td>0.893530</td>\n",
       "      <td>0.900516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.339800</td>\n",
       "      <td>1.024029</td>\n",
       "      <td>0.893378</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.887910</td>\n",
       "      <td>0.889581</td>\n",
       "      <td>0.893378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9895078c10a04d989d7a49ffb452f52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=782, training_loss=1.6624924447530371, metrics={'train_runtime': 761.0282, 'train_samples_per_second': 131.401, 'train_steps_per_second': 1.028, 'total_flos': 0.0, 'train_loss': 1.6624924447530371, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# 12m 41.0s\n",
    "# 58m 20.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all-nli-test_cosine_accuracy': 0.8955969133000454,\n",
       " 'all-nli-test_dot_accuracy': 0.10062036616734756,\n",
       " 'all-nli-test_manhattan_accuracy': 0.8875775457709184,\n",
       " 'all-nli-test_euclidean_accuracy': 0.8895445604478741,\n",
       " 'all-nli-test_max_accuracy': 0.8955969133000454}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Optional) Evaluate the trained model on the test set, after training completes\n",
    "test_evaluator = TripletEvaluator(\n",
    "    anchors=test_dataset[\"anchor\"],\n",
    "    positives=test_dataset[\"positive\"],\n",
    "    negatives=test_dataset[\"negative\"],\n",
    "    name=\"all-nli-test\",\n",
    ")\n",
    "test_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save the trained model\n",
    "# model.save_pretrained(\"models/mpnet-base-all-nli-triplet/final\")\n",
    "model.save_pretrained(\"models/mpnet-base-all-nli-triplet-128/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. (Optional) Push it to the Hugging Face Hub ... Nope!\n",
    "# model.push_to_hub(\"mpnet-base-all-nli-triplet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
