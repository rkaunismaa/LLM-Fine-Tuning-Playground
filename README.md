# LLM-Fine-Tuning-Playground

This repo will contain various examples of fine tuning large language models.

*** mamba activate ftllm ***

## Monday, May 13, 2024

Working through [peft_finetuning.ipynb](https://github.com/meta-llama/llama-recipes/blob/main/recipes/finetuning/huggingface_trainer/peft_finetuning.ipynb)

5) mamba install conda-forge::sentencepiece
6) pip install llama-recipes (notice the mis-spelling of recipes)

## Sunday, May 12, 2024

Noteable links:

* [Using and Finetuning Pretrained Transformers](https://magazine.sebastianraschka.com/p/using-and-finetuning-pretrained-transformers)
* [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)
* [Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU](https://huggingface.co/blog/trl-peft)
* [A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using Hugging Face Transformers, Accelerate and bitsandbytes](https://huggingface.co/blog/hf-bitsandbytes-integration)

## Saturday, May 11, 2024

Starting to run through the notebook 'Causal_models_like_Gemma_2B_finetuning_on_SamSum.ipynb', and looks like I have more stuff to install ...

 1) mamba install conda-forge::huggingface_hub
 2) mamba install conda-forge::ipywidgets
 3) pip install evaluate
 4) pip install rouge-score


